# -*- coding: utf-8 -*-
"""ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i-8RrikJuxHTfxrOzeDGv-gGBppIwRzX
"""

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler

# --------------------------
# Step 1: Load and preprocess the data
# --------------------------
iris = load_iris()
X = iris.data
y = iris.target.reshape(-1, 1)

encoder = OneHotEncoder(sparse_output=False)
y = encoder.fit_transform(y)

scaler = StandardScaler()
X = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

np.random.seed(42)

input_neurons = X_train.shape[1]   # 4 features
hidden_neurons = 6                 # you can experiment
output_neurons = y_train.shape[1]  # 3 classes
learning_rate = 0.1
epochs = 5000

W1 = np.random.uniform(size=(input_neurons, hidden_neurons))
b1 = np.zeros((1, hidden_neurons))
W2 = np.random.uniform(size=(hidden_neurons, output_neurons))
b2 = np.zeros((1, output_neurons))

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def sigmoid_derivative(x):
    return x * (1 - x)

def softmax(x):
    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))
    return exp_x / np.sum(exp_x, axis=1, keepdims=True)

for epoch in range(epochs):
    # Forward propagation
    hidden_input = np.dot(X_train, W1) + b1
    hidden_output = sigmoid(hidden_input)

    final_input = np.dot(hidden_output, W2) + b2
    final_output = softmax(final_input)

    # Compute error
    error = y_train - final_output

    # Backpropagation
    d_output = error
    d_hidden = np.dot(d_output, W2.T) * sigmoid_derivative(hidden_output)

    # Update weights
    W2 += np.dot(hidden_output.T, d_output) * learning_rate
    b2 += np.sum(d_output, axis=0, keepdims=True) * learning_rate
    W1 += np.dot(X_train.T, d_hidden) * learning_rate
    b1 += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate

    # Print loss every 500 epochs
    if (epoch + 1) % 500 == 0:
        loss = np.mean(np.square(error))
        print(f"Epoch {epoch+1} - Loss: {loss:.4f}")

hidden_input_test = np.dot(X_test, W1) + b1
hidden_output_test = sigmoid(hidden_input_test)
final_input_test = np.dot(hidden_output_test, W2) + b2
final_output_test = softmax(final_input_test)

# Predictions
predictions = np.argmax(final_output_test, axis=1)
true_labels = np.argmax(y_test, axis=1)

accuracy = np.mean(predictions == true_labels)
print("\nâœ… Model Accuracy on Test Data:", round(accuracy * 100, 2), "%")

import pandas as pd

df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['target'] = iris.target
df['flower_name'] = df['target'].apply(lambda x: iris.target_names[x])

print(df.head(100))  # show first 5 rows

import matplotlib.pyplot as plt

# Plot petal length vs petal width
plt.figure(figsize=(8,6))
for flower in iris.target_names:
    plt.scatter(
        df[df['flower_name'] == flower]['petal length (cm)'],
        df[df['flower_name'] == flower]['petal width (cm)'],
        label=flower
    )

plt.xlabel('Petal Length (cm)')
plt.ylabel('Petal Width (cm)')
plt.legend()
plt.title('Iris Flower Categories')
plt.show()